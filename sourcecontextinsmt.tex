\documentclass[11pt]{article}
%\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\special{papersize=210mm,297mm} % to avoid having to use "-t a4" with dvips 
%\setlength\titlebox{6.5cm}  % You can expand the title box if you really have to
\usepackage{graphicx}
\usepackage{placeins}
\usepackage{framed}
\usepackage{pbox}
\usepackage{amsmath}
\usepackage{supertabular}
\usepackage{algorithm} 
\usepackage{algpseudocode} 
\usepackage{caption}
\usepackage[utf8]{inputenc}
\usepackage{gb4e}
\usepackage{natbib}

\let\proof\relax
\let\endproof\relax
\usepackage{amsthm}
\newtheoremstyle{break}
  {\topsep}{\topsep}%
  {\itshape}{}%
  {\bfseries}{}%
  {\newline}{}%
\theoremstyle{break}
\newtheorem{exmp}{Example}[section]

\title{Unsupervised classifier-based modelling of source-side context information for Statistical Machine Translation}


\author{Maarten van Gompel \& Antal van den Bosch \\
 Centre for Language Studies \\
  Radboud University Nijmegen \\
  {\tt proycon@anaproy.nl}}

%\date{}


\begin{document}
\maketitle

\begin{abstract} 
We present in-depth research into the modelling of source-side
context to improve Phrase-based Statistical Machine Translation. Statistical
Machine Translation systems typically consist of a translation model and a
language model. The former maps phrases in the source language to the target
language, without regard for the context in which the source phrases occur. The
latter models just the target language, and acts as a target-side model of
context information after translation. We attempt to independently reproduce a
line of existing research and test whether considering context information
directly in the translation model has a positive effect on translation quality.
We furthermore investigate various ways classifier-based models can be
integrated into Statical Machine Translation.  We will use proven techniques
from Word Sense Disambiguation, effectively integrating WSD techniques in
Statistical Machine Translation. Our approach is classifier-based and our focus
is exclusively unsupervised, we therefore do not include any additional linguistic
features. 
\end{abstract}

\section{Introduction}

In Phrase-based Statistical Machine Translation (SMT) the problem of
translating an input sentence from a source language to a target language is
perceived as a game of probabilities and a search for the most probable
translation option.  These probabilities are expressed in a number of models
that specialize in a certain aspect relevant to the translation process. The
``phrase-based'' characteristic is due to phrases being the building blocks of
the translation model. This can be contrasted to earlier approaches in
Statistical Machine Translation which started as word-based.  Phrases in this
sense have to be perceived simply one or more words, i.e.  n-grams of variable
length (including unigrams). Moreover, they are not at all required to form a
proper linguistic constituent of any kind.

Two models are at the core of phrase-based SMT: first there is the translation
model which maps the translation phrases in the source language ($s$) to
phrases in target language ($t$), this mapping is expressed as a vector of
probabilities, most notably $P({phrase}_s|{phrase}_t)$ and
$P({phrase}_t|{phrase}_s)$. This component can be seen to model the notion of
``semantic faithfullness''; if you translate a phrase from one language to
another, you want the meaning to be preserved as accurately as possible. The
second core model is the language model, this model in monolingual in nature
and models \emph{the target language}. It models what words are likely to
follow others and can be interpreted as modelling the ``syntactic fluency''
notion of translation; a translation should be in a natural word-order and
sound natural. A Machine Translation \emph{decoder} optimises a log-linear
model of these two, and additional other, models. Given an input sentence in
the source language, it searches through a vast space of all ``possible''
translation options, most non-sensical, for a path maximising the probabilities
according to each of the models, taking into account different weights they may
be assigned.

The study we currently present focusses on the role of surface-form context
information in this SMT process. The Language Model effectively models context
for the target language, it makes sure that a translated phrase fits nicely
along other translated phrases. But in SMT there is no component modelling
context for the source-language, whereas intuitively source-side context may
provide a powerful cue for translation. Consider the word ``bank'' and its
Spanish translation in examples~\ref{ex:bank1} and \ref{ex:bank2}.

\begin{exe} %gb4e package
\ex \textbf{English:} I don't trust the bank. \\
    \textbf{Spanish:} No me fio del banco.
\label{ex:bank1}

\ex \textbf{English:} The boat headed towards the bank of the river. \\
    \textbf{Spanish:} El barco se dirigió hacia la orilla del río.
\label{ex:bank2}
\end{exe}

The same English word, ``bank'' may express multiple semantic senses, some of
which are expressed by different words in Spanish. Source-side context
information may provide valuable clues to what sense is being employed, and
therefore what translation is correct.  The words ``boat'' and the phrase ``of
the river'' in example \ref{ex:bank2} make it pretty clear that we are using
bank in its maritime sense. Example \ref{ex:bank1} is less obvious, but the
word ``trust'' could be seen to be a cue when the noun ``bank'' denotes a
financial institution.

These examples are meant to illustrate the intuition that is behind our
research hypothesis. We hypothesise that the inclusion of source-side context
information in the translation model improves translation results, as the
context helps in providing a more accurate disambiguation. A counter-hypothesis
to this would be that whilst source-side context information is not modelled
explicitly, it is implicitly captured by the combination of translation model
and language model, and explicit modelling has no added value.

There is clear and obvious overlap between what we do here and the field of
Word Sense Disambiguation (WSD). We effectively test an integration of proven
techniques from WSD in Statistical Machine Translation, and apply these to
phrases rather than just words.

WSD systems often employ a variety of linguistic features. The focus of our
study, however, is fully unsupervised. We are interested only in the surface
forms, the text as-is, and stay as close as possible to vanilla Phrase-Based
Statistical Machine Translation, without using any language-specific external
resources. In this fashion, we attempt to assess the merit of source-side
context information as it is in its unmodified form. 

Not introducing extra data for the translation system means our goals have to
be set more modest as well. We can not expect the same gains as are achieved by
introducing extra data from supervised sources.

\section{Previous research}

The idea to integrate WSD approaches in SMT is not new, nor is the idea to use
source-side context information to disambiguate in translation. Various studies
have been conducted with mixed results. In the early days of SMT,
\cite{GarciaVarea+02} already explicitly modelled source-side context in a
maximum entropy model for word-based SMT, and report slightly improved error
rates on a translation task.

\cite{CarpuatWu05} were the first to directly tackle the question whether
full-scale WSD models were beneficial to translation quality when integrated in
SMT systems, and thus their work forms important foundation for our own study.
Their approach uses an ensemble classification model that integrates
position-sensitive, syntactic, and local collocational features, which has
proven itself in competitive WSD tasks. This includes linguistic features such
as part-of-speech tags and lemmas, as well as more complex syntactic relations.
They test for a single Chinese-to-English test-set only, and only use BLEU,
which raises some questions on whether their conclusions would hold on
different language pairs, test sets, and using different evaluation metrics.

\cite{CarpuatWu05} place strong focus on the WSD model rather than the SMT
model, whereas we place more focus on the SMT model and the integration method,
and keep the ``WSD-model'' relatively simple. Furthermore, the method they
employ a simpler word-based form of Statistical Machine Translation and the
level of integration seems limited.

Despite their efforts, they reach the surprising conclusion that inclusion of
WSD techniques does \emph{not} yield better translation quality. Will these
results hold in a more modern Phrase-based Statistical Machine Translation
approach?

Two years later they expanded their study to full phrasal units
\citep{CarpuatWu07} and, for the first time, found results that did support the
hypothesis that SMT benefits from the integration of WSD techniques. They now
focus on better integration in \emph{phrase-based} SMT: ``Rather than using a
generic SenseEval model as we did in \cite{CarpuatWu05}, here both the WSD
training and the WSD predictions are integrated into the phrase-based SMT
framework.'' \citep{CarpuatWu07}. They also broaden their use of evaluation
metrics, yet still test on only Chinese to English.

The work of \cite{Gimenez+07} is similar, they use support vector machines to
predict the phrase translation probabilities for the phrase-translation table
component of SMT, rather than relying on the context-unaware Maximum Likehood
Estimate the statistical process produces. The feature vector for their
classifiers consists of both local context as well as global context features.
In addition to the surface forms of the words, they do rely on shallow
linguistic features such as Part-of-Speech tags and lemmas. They conduct a
manual evaluation judged on fluency and adequacy, and conclude that considering
context improves adequacy, yet does not benefit fluency. They remark that the
integration of the classifier probabilities in an SMT framework needs further
study, which is something that will indeed be a focus in our present study.

The year 2007 saw a culmination of various studies integrating WSD techiques in
SMT using classifiers. A third study in this trend was \cite{Stroppa+07}. They
have a strong focus on the word form, as does this present study, and add only
part-of-speech features. On IWSLT 2006 data for Chinese-English and
Italian-English, they achieve a significant improvement for the former, whereas
the BLEU score for the latter fails to pass the significance test. We will
attempt to reproduce these experiments in this study.

Source-context aware translation has also been attempted outside of the
predominant statistical machine translation framework. \cite{MBMT} implement a
simple form of example-based machine translation that is word-based and relies
chiefly on classifiers for the translation model component. Two studies derive
from the same concept while transcending a word-based paradigm:
\cite{MARKERBASED} use chunks delimited by common markers. and \cite{PBMBMT}
attempts a full extension to phrases similar to SMT. Although positive results
are achieved in the latter study, it does not rival state-of-the-art SMT.

The most important and complete study we build upon is \cite{Rejwanul+11},
which in turn draws from the majority of the aforementioned studies, and
provides an extensive comparison between them. Their study finds that including
such linguistically-informed contextual features in general produces
improvements.  The main contrast between our study and theirs is that they
focus on a variety of linguistically-informed contextual features, whereas we
depart from a purely unsupervised angle and intend to settle some of the
conflicting reports whether this may lead to an improvement in translation
quality. A notable focus in our study will be possible methods of integrating the
classifier probabilities in the SMT, as recommended also by \cite{Gimenez+07}.


\section{Methodology}
\label{ref:methodology}

Like most of the latest studies before us, we approach the machine translation
problem in a phrase-based fashion, which has superseded the simpler word-based
based paradigm for quite some time. This means that phrases, defined as a
sequence of one or more words (that need not form a linguistic entity in any
way!), form the basic building blocks of our translation model. The problem of
translating a sentence is decomposed into the problem of translating its phrasal
subparts and combining the results in the best order.

In describing our methodology, we first focus on the problem of phrasal
translation, adding in the source-side context component. This shall be done
using classifiers. Then we address how this can be integrated into a
phrase-based Stastical Machine Translation decoder, which also takes care of
ordering aspect. 


\subsection{Modelling source-side context with classifiers}

In line with several previous studies \citep{Rejwanul+11,PBMBMT,
Stroppa+07,MARKERBASED}, we make use of memory-based classifiers to build a
translation model informed by source-side context information. More
specifically, we will be using IB1 \citep{IB1}, an implementation of k-Nearest
Neighbours; IGTree \citep{IGTree}, an optimised and lossless tree-based approximation thereof;
and TRIBL2, a mixture model of the two. 

These algorithms are all implemented in the
software Timbl \citep{TIMBL}\footnote{\url{http://ilk.uvt.nl/timbl}} and
are well-suited for symbolic data and highly multivariate classes.
Moreover, memory-based classification has been a proven solution in the field
of Word Sense Disambiguation \citep{SENSEVAL2,WSD2}.

When speaking of the $k$ nearest neighbours in the implementation of IB1,
IGTree and TRIBL2, we are actually referring to the neighbours at nearest
distance $k$. So even with $k=1$ we may be talking about multiple data points
that are all at equal distance.

%(these two paragraphs are paraphrased from my PBMBMT thesis, not sure to cite
%or prevent for risk of over-self-citation here)
IGTree compresses the instance base into an ordered decision tree structure at
training time, and issues look-ups in this tree structure at test time. Unlike
other top-down induced decision tree methods such as C4.5, features in IGTree
are tested in a fixed order. This is computed \emph{only once and in advance}
for all features. This order is determined using metrics such as
\emph{information gain} or \emph{gain ratio}. They determine the relative
informativeness or disambiguating power of the feature and provide a ranking of
all features. 

IGTree's performance relies on the differences in information gain between
features. If these are small then IGTree may perform significantly below IB1
\citep{TIMBL}. A hybrid approach called TRIBL2 \citep{TIMBL} starts out with
IGTree and switches to a IB1 variant when a value mismatch occurs in the tree.
In this study, we therefore opt to use TRIBL2 over plain IGTree, but only when
using IB1 would have a prohibitively large impact on performance.

In our classifier-based translation model we will be modelling the probability
of a target phrase ($t$) given a source phrase ($s$) and context information
($C$). We can thus express this as $P(t|s,C)$.  \cite{Stroppa+07} state that
direct estimation of this probability using relative frequencies would result
in overestimation of large phrases, and that therefore a smoothing factor is
required. They proceed to say that through memory-based classification we
implicitly introduce precisely such a smoothing factor.

Given a source phrase and context information, the classifier yields classes
corresponding to target phrases, with an associated weight. After
normalization, these can be considered a posterior distribution of
target phrases. 

We primarily focus on the modelling of local context, i.e. words in the
immediate vicitinity of the source phrase. Take $w_0$ to be the first word of
the source phrase $s$, then for a local context size of $n$ words to the left and
$m$ to the right we construct the feature vector $C$ as follows:

\begin{equation}
  C = \langle w_{-n} .. w_{-1} , s , w_{|s|+1} .. w_{|s|+m} \rangle
\end{equation}

For context words out of the sentence's bounds, placeholders are used instead.

Now there are two ways in which we can construct a classifier:

\begin{itemize}
  \item \textbf{Monolithic classifier} -- One aggregated classifier for all
    source phrases.
  \item \textbf{Classifier experts} -- One classifier per source phrase.
\end{itemize}

In this study we will use and compare both methods, which is, for the task at
hand, the first such a comparison in the literature as far as we know.

For the monolithic classifier, the first feature in the ranking will always be
$s$. Nevertheless, it is quite conceivable that a match for the context is not
found and the classifier proceeds to match on another feature. To prevent
situations in where the classifier falls back to a completely different source
phrase, and thus comes up with unrelated translation options, we enforce that
the source phrases need to match exactly, which is what \cite{Stroppa+07} do as
well.

For the classifier experts, on the other hand, the source phrase is the least
powerful feature in the ranking, as it is shared amongst all instances. We
therefore simply omit it from the feature vector.

\subsection{Training}

The translation model is trained on parallel corpus data. We follow a common
MT pipeline and at the end derive classifier training data.

Given an a tokenised and sentence-aligned parallel corpus, we iteratively learn
word alignments using GIZA++ \citep{GIZA}. Then we identify and extract phrase
pairs using the {\em grow-diag-final}\/ algorithm \citep{OchNey2003}. The
result is a phrase-translation table mapping source phrases to target
phrases, along with associates scores which we will discuss in the next
section. This phrase-translation table effectively constitutes the translation
model.

The translation model would be finished if we would want to leave it to be
non-context-informed. We have some additional steps to perform to train our
context-informed classifiers. We take the phrase-translation table, along with
the parallel corpus, as a basis for extracting training instances.

We build indexed pattern models of all source phrases and target phrases that
occur on their respective side the parallel corpus, and which also occur in the 
phrase-translation table. An indexed pattern model maps each distinct phrase to
the locations in the corpus where it occurs.  Additionally, a reverse index is
included in the model for the target-side of the corpus, which maps any given
$(sentence, token)$ position to a set phrases that begins at that position.
This is computed using the software \emph{colibri-core}
\footnote{http://proycon.github.io/colibri-core}, which takes care of a
losslessly compressed in-memory representation for all phrases, and allows us
to cope with large corpora.

Given these two pattern models $M_{source}$ and $M_{target}$ we can quickly and
efficiently extract the context for each phrase pair, as shown in simplified
form in Algorithm~\ref{alg:featureextract}.  

\begin{algorithm}
\caption{Algorithm for feature extraction for training classifiers.  Take $n$
again to be the left context, $m$ to be the size of the right context, and
$w{(i,j)}$ to denote the word in the source corpus in sentence $i$, token $j$.
The vector $C$ represents the context information and constitutes the feature
vector.  The algorithm will return a list containing two-tuples $(C,t)$.  }
\label{alg:featureextract}
\begin{algorithmic}
\State instances $\gets []$
\For {$(s \in M_{\text{source}}, t \in M_{\text{target}})$}
  \For {$i \in (M_{\text{source}}[s] \cap M_{\text{target}}[t])$}
    \For{$j \in M_{\text{source}}[s][i]$}
        \State $C \gets \langle w_{i,j-n} \ldots w_{i,j-1}, s, w_{i,j+|s|+1} \ldots w_{i,j+|s|+m} \rangle$
        \State \Call{instances.append}{$(C, t)$} 
      \EndFor
  \EndFor
\EndFor \\
\Return{instances}
\end{algorithmic}
\end{algorithm}
    
This algorithm is implemented in \emph{colibri-mt}
\footnote{https://github.com/proycon/colibri-mt}.

The return instances can be stored directly, either in a single model for the
monolithic approach or in separate models for each $s$ for the classifier
expert approach. A final training phase then computes the feature ranking and
transforms this data into the instance base format required for Timbl.

When extra training data for the classifier(s), it may well happen that either
1) an $(s,t)$ pair only occurs once, or 2) a pattern $s$ occurs in multiple
context but all map to the same $t$. In such cases, a context-informed
classifier clearly has no added value and therefore such instances are omitted from the training data.  

\subsection{Integration in an SMT Decoder}
\label{sec:smtintegration}

The task of an SMT decoder is to find the best translation amongst a vast pool
of possible translation hypotheses. The best translation hypothesis is the
translation hypothesis that maximises a log linear combination and is sought
after in a beam-search algorithm. This log-linear combination draws from
various models, such as a translation model (i.e. the phrase-translation
table), a target-language model, and optionally additional models such as a
distortion model or word-reordering model.

The translation model is a mapping of the set of source phrases ($S$) to the
set of target phrases ($T$). Each phrase-pair $(s,t)$ where $s \in S$ and $t
\in T$ is in described by a score vector indicating the likelihood of
translation. This score vector most notably consists of the probababilities
$p(s|t)$ and $p(t|s)$. In addition, lexical weighting probabilities $lex(s|t)$
and $lex(t|s)$ express the probability of a phrase-pair word-by-word, and are
often included as components in the score vector. During decoding, the total
score of the translation model and other models is expressed as a log-linear
combination, in which different weights can be assigned to each of the
components of the score vector. These weights are meta-parameters to the task and
are typically optimised automatically on development data using for instance
Minimum Error Rate Reduction \citep{MERT}.

The probability $p(t|s)$ is the one we are interested in. Recall that the
classifiers attempt to model $p(t|s,C)$, where $C$ constitutes the vector of
context information. The hypothesis under investigation in the present study is
that $p(t|s,C)$ is a more accurate measure than $p(t|s)$.

The state-of-the art SMT decoder used in the majority of MT studies is Moses
\citep{MOSES}. However, it offers no facilities to take source-side context
information in account. We had to consider three options to achieve our goal of
integrating source-side context : 1) creating a new decoder; 2) enhancing
Moses; or 3) using a bypass method. Although we initially set out to create a
new decoder, it proved to be too difficult to attain the same quality as Moses.
We therefore decided, in line also with most of the literature, to follow the
third option, it is easiest and allows us to use Moses as a black box.

The bypass method is our \emph{discriminative translation filtering}
step \citep{Rejwanul+11}, it performs context-aware classification in a
pre-processing step, namely through alteration of the phrase-translation table,
and bypasses the need to alter the decoder in any way. We effectively take each
sentence individually and ensure that the entries in the phrase-translation
table are explicitly tuned to the source-side context. The output of the
classifier(s) acts as the filter and constrains the translations options, as
well as adjusts the score vector. Each instance of a source phrase will get a
separate entry in the phrase-translation table, as opposed to one source phrase
applying to all instances in the test data. 

To achieve this, each source phrase in the phrase-translation table is replaced
by a representation of its position in the test data, e.g.  $(1,0)$ for first
sentence, first word.  This is done using the software \texttt{colibri-mt}. It
creates an indexed pattern model on the test data, constrained by the phrases
in the phrase-translation table. This thus constitutes a mapping of all distinct
source phrases in the phrase-translation table to the indices in the test
corpus that are instances of these phrases.

Subsequently we invoke the classifier(s) and construct the altered
phrase-translation table as shown in Algorithm~\ref{alg:contextmoses}.

\begin{algorithm}
\begin{algorithmic}
  \For {$s \in M_{\text{test}}$}
  \For {$(i,j) \in M_{\text{test}}[s]$}
    \State $C \gets \langle w_{i,j-n} \ldots w_{i,j-1}, s, w_{i,j+|s|+1} \ldots w_{i,j+|s|+m} \rangle$
    \State $[(t, p(t|s,C) )] \gets$ \Call{classify}{$s,i,j,C$}
    \State {\Call {appendtophrasetable}{$s,i,j,[(t, p(t|s,C)]$}}
  \EndFor
\EndFor
\end{algorithmic}
\caption{Classifier invocation on test data. Take $M{\text{test}}$ to be the pattern
model of the test data, i.e. a map of source phrases occuring in the test
data, and $[(t,p(t|s,C))]$ to be a list of translation options ($t$) with
associationed probability $p(t|s,C)$.}
\label{alg:contextmoses}
\end{algorithm}

In Algorithm~\ref{alg:contextmoses} we examine each source phrase in turn, find
where it occurs in the test data ($i,j$) using the pattern model
($M_{\text{test}}$), and extract context information ($C$). The context
information constitutes our feature vector, with which we invoke the
appropriate classifier. This is either the monolithic classifier, or the
classifier expert pertaining to the source phrase under consideration. The
result of this classification is a distribution of translation options for that
source phrase in the given context, along with a classifier score for each
option. After normalisation, this score is $p(t|s,C)$. We now have two score
weighting methods for integrating this in the score vector for the phrase pair:

\begin{itemize}
  \item \textbf{Replace} - Replace the $p(t|s)$ probability with $p(t|s,C)$
  \item \textbf{Append} - Leave the existing $p(t|s)$ as it was, but append
    $p(t|s,C)$ as a new score to the score vector.
\end{itemize}

The score weighting of choice is applied and the data is entered into the
altered phrase-translation table. The source phrase takes the form of a
sequence of $(i,j)$ indices, rather than the actual words..  The test data is
replaced with a series of consecutive positions as well. These two altered data
sets are now the input to Moses, which can now run unmodified. 

\section{Experiments}

We conduct a number of experiments to assess whether integration of
context-informed classifiers in Statistical Machine Translation leads to
an improvement in translation quality. 

We will use various corpora and various language pairs.

\subsection{Evaluation}

Translation quality will be assessed along five widely-used automated metrics,
as human evaluation is prohibitively expensive:

\begin{enumerate} %paraphrased from PBMBMT thesis
\item \textbf{BLEU} - BLEU \citep{BLEU} is probably the most widely-used metric
in Machine Translation. It computes a weighted average of $n$-gram overlap
between the system output and reference output. The score thus increases as
more $n$-grams reference are found in the system output.
\item \textbf{NIST} - NIST intends to improve upon BLEU, it takes into account
how informative a particular $n$-gram is by assigning more weight to rare
$n$-grams and less to highly-frequent $n$-grams.  \item \textbf{METEOR} -
METEOR \citep{METEOR} attempts to outperform BLEU and attempts to emulate human
judgement tasks. Unlike the prior metrics, it places emphasis on recall rather
than precision.
\item \textbf{Word-Error Rate (WER)} - This is a simple metric derived from the
minimum edit-distance, i.e. Levenshtein, algorithm. It counts the number of
substitutions, insertions and deletions necessary to transform the translation
into the reference sentence. Here words are used as the basic unit. The lower
the score, the more similar the translation is to the reference.  
\item \textbf{Position Independent Word Error Rate (PER)} - This is a variant of the
metric above, but here the order of the words is not taken into account. Any
ordering of the same words will have the same score. The lower the score, the
more similar the translation is to the reference.
\end{enumerate}

\subsection{Baseline}

For each experiment, we construct a non-context informed baseline. This
baseline does make use of our full pipeline, i.e. the bypass method described
in Section~\ref{sec:smtintegration}, but it simply does not invoke the
classifiers.  We do this to ensure the only difference is the actual
integration of context information, and that differences in result can not be
attributed to minor ideosyncracies of the implementation.












\bibliographystyle{spbasic}
\bibliography{sourcecontextinsmt}



%cross-domain testing

\end{document}
